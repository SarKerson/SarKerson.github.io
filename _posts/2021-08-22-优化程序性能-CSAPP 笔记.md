---
layout:     post
title:      优化程序性能
subtitle:   Chapter 5, Optimizing Program Performance - CSAPP Note
date:       2021-08-22
author:     Eric.Y
catalog: true
tags:
    - os
---


# 第五章 优化程序性能

# 0. 优化之路咋走？

首先需要知道优化之路可以怎么走，下面摘自 CMU 的公开课 slides。主要有两方面因素：

代码风格：良好的数据结构与算法思想，循环、变量等人为因素；
编译器与操作系统：了解编译器优化，从汇编、profile 等角度分析性能瓶颈，了解操作系统层面因素；

![img](https://pic4.zhimg.com/v2-52dafcb512911ab2b882c041cc3cb9bf_r.jpg)

---

# 1. 量化程序性能

使用 CPE（Cycles Per Element）来量化程序性能。其表示每个循环执行了多少个时钟周期（可以预估执行了多少个指令）。

对于一个“4GHz”的处理器而言，时钟运行的频率是每秒 `4x10^9` 个周期，即`一个时钟周期 = 0.25ns`。

例如，**将程序的循环的** **CPE** **从 9 优化到 6，表示我们将程序中的每个循环，从消耗 9 个时钟周期，优化到 6 个时钟周期，节省了 3 个时钟周期。**

![img](https://pic3.zhimg.com/v2-864b70095ba5024e206de2adceac5696_r.jpg)

CPE 其实就是右图中的斜率，**我们的优化目标是尽可能让直线躺平。**

![img](https://pic1.zhimg.com/v2-84870d35766af848946b06c997c75a20_r.jpg)

## 为什么要用 CPE？

其实就是比较直观，而且容易跟运算单元的速度进行关联，**可以很方便地估计出优化的幅度**。

**下面是常见操作的CPE：**

![img](https://pic3.zhimg.com/v2-de7a80a0273f5bd7777f91bbf6a51f32_r.jpg)

下面是对 capacity、latency、issue 的图形化描述：

1. capacity：描述处理器单位时间能过处理的指令数量
2. latency：描述单位指令执行时间
3. issue：描述相同指令之间的执行间隔（可以翻译为发射时间）

![img](https://pic4.zhimg.com/v2-9ea27582d24adcc0edb4e9c9a135b6d3_r.jpg)

**通过各个模块的 CPE，快速估算出优化的幅度：**

> 对于某台机器 load=2, mul=3, add=1

1. 左图：关键路径消耗 (load+mul)*n=(2+3)*n=**5n 个时钟周期**
2. 右图：关键路径消耗 (load+mul+mul)*n/2=(2+3+3)*n/2=**4n 个时钟周期，速度提高 20%**

![img](https://pic4.zhimg.com/v2-bdf91c3d07ed070f8ffabad1a1f38643_r.jpg)

当然，这个 CPE 在实际工作中计算出来是比较麻烦的，但是对于了解常见汇编指令的速度还是有一定帮助。

---

# 2. 编译器优化的能力和局限性

## 编译器能做啥？

这里介绍几个编译器能做的优化。

优化计算表达式：将复杂表达式转换为简单表达式，例如用位操作来代替乘法；

![img](https://pic3.zhimg.com/v2-0c6fdf42f60d30b2d9e23ba9ccdcfe0a_r.jpg)

使用公共变量：使用临时变量等方式来避免重复几计算；

![img](https://pic3.zhimg.com/v2-4876145c4a99ab70ff6bda94a3d06352_r.jpg)

## 编译器挫在哪？

### 挫一：处理函数调用

![img](https://pic3.zhimg.com/v2-b28bec969a58c881677b441585a503d6_r.jpg)

**为什么编译器不能够发现，并将** `strlen` **提取到循环外？**

![img](https://pic1.zhimg.com/v2-5fbb65b4fe971565c69f10791da31014_r.jpg)

- 函数可能有副作用，例如修改某个全局变量
- 函数不一定是幂等的，例如依赖某个全局变量

> 编译器倾向于把函数调用当作黑盒，因为无法知道其副作用，所以不会对此进行优化。 —— 鲁迅

### 挫二：内存别名引用

![img](https://pic1.zhimg.com/v2-920888a4c2d7010a91086abbc4731738_r.jpg)

![img](https://pic4.zhimg.com/v2-5d07e083c4c3f0bee6926f69ffbba1b3_r.jpg)

**编译器不能优化这点吗？**

看上去编译器似乎能够优化这点，但是编译器会假设两个指针地址可能相同，因此必须非常谨慎，躺平不动。

![img](https://pic1.zhimg.com/v2-182e16d4946b894686efb14e72f13e9c_r.jpg)

> 程序员要养成使用局部变量的习惯，显式地告诉编译器，这里没有内存别名。 —— 鲁迅

---

# 3. 现代微处理器

到目前为止，我们提及到的优化技巧，都不依赖于目标机器的任何特性。我们目前的优化，只是简单的降低了过程调用的开销、避开了编译器的挫。如果要进一步进行优化，必须考虑利用现代微处理器的优化，也就是处理器用来执行指令的底层系统设计。

![img](https://pic2.zhimg.com/v2-9c33589c72e723cddf021d921976b30d_r.jpg)

这样的处理器，在工业界称为超标量（Superscalar），**即每个时钟周期可以执行多个指令，且是乱序执行**。整个处理器分为两大部分，指令控制单元（ICU）和执行单元（EU）。

![img](https://pic2.zhimg.com/v2-aca2a7b65d4f556495410e48088c2d8d_r.jpg)

- **指令控制单元**：从高速缓存中取指、译码，生成一组 low level 的基本操作；
- **执行单元**：执行上述基本操作；包括多个功能单元，比如 arith（算术运算）、load（内存读）、store（内存写）等等，分别负责各自独立的计算和存取内存操作。

当程序遇到分支的时候，程序可能有两个前进的方向。现代处理器使用了**分支预测**技术（Branch Prediction），会猜测是否选择分支，且会预测分支跳转的目标地址。然后使用**投机执行**（Speculative Execution）技术对目标分支跳转到的指令进行取指和译码（甚至在分支预测之前就开始投机执行）。如果之后确定分支预测错误，则会将寄存器状态重置为分支点的状态，并开始取出和执行另一个分支上的指令。所以可以看到，**分支预测错误会导致很大的性能开销。**

---

# 4. 让处理器助你一臂之力吧！

## 循环展开

![img](https://pic3.zhimg.com/v2-8361747f231f7e18824b729bba85b60a_r.jpg)

优化前后的关键路径对比，**可以看到每 2 个 Element，节省了一个 load 操作，速度提高 20%：**

![img](https://pic3.zhimg.com/v2-5f4d6cdda7330beaf4c1d909ba6348d6_r.jpg)

## 提高并行性

### 分治法

![img](https://pic1.zhimg.com/v2-a4c2a5ae6b34407ad52fa506fa295d20_r.jpg)

优化前后的关键路径对比，**可以看到每个 2 个 Element，节省了 mul 操作，速度提高 1x 多：**

- 左边关键路径：load+2*mul=8
- 右边关键路径：load+mul=5

![img](https://pic4.zhimg.com/v2-25b4ed4e4cccad04993fc2d01a30c17b_r.jpg)

### 重新结合运算

![img](https://pic1.zhimg.com/v2-591a7d89ac9e4b205aa415353aa9dda0_r.jpg)

优化前后的关键路径对比，**可以看到每个 4 个 Element，节省了 2mul+2load 操作，速度提高 2x 多：**

- 左边关键路径：(load+2mul)2=16
- 右边关键路径：2*mul=6

![img](https://pic4.zhimg.com/v2-f18d1306b38b8c0a0f3e7e955c7764b3_r.jpg)

## 小结

本质：解除数据依赖

1. 分治法：利用每个子问题的并行执行提高速度
2. 重新结合变换：解除多项式操作中，项之间的关键依赖

## 分支

### 书写容易预测的代码

[Why is processing a sorted array faster than processing an unsorted array? - Stack Overflow](https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array)

现代处理器可以很好预测分支指令的**有规律模式**。

```text
if (data[c] >= 128)
    sum += data[c];

T = branch taken
N = branch not taken


data[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...
branch = N  N  N  N  N  ...   N    N    T    T    T  ...   T    T    T  ...
       = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)


data[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118,  14, 150, 177, 182, ...
branch =   T,   T,   N,   T,   T,   T,   T,  N,   T,   N,   N,   T,   T,   T  ...
       = TTNTTTTNTNNTTT ...   (completely random - impossible to predict)
```

**[CPU 的分支預測器是怎樣工作的？](https://www.zhihu.com/question/23973128)**

![img](https://pic4.zhimg.com/v2-765bcfa1a3f9a7cb2392c7395688557b_r.jpg)

### 书写适合**条件传送**的代码

![img](https://pic2.zhimg.com/v2-a8140e15385d26862c0ca72064e3303d_r.jpg)

- **条件跳转**

![img](https://pic4.zhimg.com/v2-fb189135b7a1e068850edcab11e51d7b_r.jpg)

- **条件传送**

![img](https://pic4.zhimg.com/v2-3e10044c588dfe84a290b56be716359f_r.jpg)

**为什么条件传送更快？**

先计算，再选择结果。且这些计算没有数据依赖，可以充分利用处理器的指令流水。

## SIMD

> SIMD（**Single Instruction Multiple Data****）**即单指令流多数据流，是一种采用一个控制器来控制多个执行器，同时对一组数据（又称“数据向量”）中的每一个分别执行相同的操作从而实现空间上的并行性的技术。简单来说就是一个指令能够同时处理多个数据。

[Achieving Greater Parallelism with SIMD Instructions](https://link.zhihu.com/?target=http%3A//csapp.cs.cmu.edu/3e/waside/waside-simd.pdf)

![img](https://pic3.zhimg.com/v2-fac68f950f2acc170c6ea3bd4d48fb9e_r.jpg)

# 5. 小结

- 良好的编码习惯
  - 数据结构与算法
  - 消除编译器优化障碍
    - 过程调用
    - 内存别名引用
  - 优化循环
- 帮助机器更好地优化
  - 利用指令并行
  - 避免不可预测的分支
  - 提高指令缓存命中率

**本文所讲的这些优化方法，在大部分编译器中都已经实现了。**但是它们有可能不会实行这些优化，或需要我们手动设置更高级别的优化选项才行。所以，**作为一个程序员，我们应该做的是尽量引导编译器执行这些优化，或者说排除阻碍编译器优化的障碍。**这样可以使我们的代码在保持简洁的情况下获得更高的性能。迫不得已时，我们才去手动做这些优化。

另外，循环展开、多路并行并不是越多越好。因为寄存器的个数是有限的，x86-64 最多只能有 12 个寄存器用于累加，如果局部变量的个数多于 12 个，就会被放进存储器，反倒严重拉低程序性能。

---

# 6. 身边活生生的例子

## 数据依赖

组内有同学反馈，跑 pprof 的时候，发现一个简单的函数调用占用了 20% 左右的 CPU 时间，这个函数只是取了一个对象里面的列表元素做简单计算。只不过对象潜套了多个指针，于是怀疑是指针嵌套的问题。

我把对应的代码抽出来，对比了直接引用（左）与指针嵌套引用（右）的汇编代码区别：

![img](https://pic2.zhimg.com/v2-a11bafb119b4992bf2f2b041e795ced9_r.jpg)

可以发现，右侧代码中，红圈中的 5 行指令都是在 DX 寄存器中进行操作，形成了数据依赖，无法充分利用指令流水。

## 指令缓存

> 摘自内部 infra 组同学的一篇文章，描述的是 RPC 框架一个小改动带来的性能问题。

事故现场：[Mergely - Diff online, merge documents](https://link.zhihu.com/?target=https%3A//editor.mergely.com/HPqQpVCJ/)

可以看到，相比旧版本的生成代码，该 commit 在返回错误的时候会额外包装一下：

```Go
if err := ...; err != nil {
    return thrift.PrependError(fmt.Sprintf("%T read field x 'xxx' error: ", p), err)
}
```

而旧版本的生成代码是直接返回的错误：

```Go
if err := ...; err != nil {
    return err
}
```

虽然这些只是在发生错误的时候才会调用到，在正常流程中不会用到，但是生成的汇编代码中这段逻辑占了相当大的比例：

![img](https://pic4.zhimg.com/v2-a7628ca8d1e68fc73db83d78e0c64fa7_r.jpg)

而 Go 的编译器并没有帮我们重排这些指令，导致在真正运行的时候，L1 cache miss 大大提高，极大地降低了性能。

---

# 拓展阅读

以下是 golang 一些性能分析的拓展阅读，有兴趣可以看。

- [Golang 性能测量和分析](https://link.zhihu.com/?target=https%3A//github.com/sxs2473/go-performane-tuning/blob/master/3.%E6%80%A7%E8%83%BD%E6%B5%8B%E9%87%8F%E5%92%8C%E5%88%86%E6%9E%90/%E6%80%A7%E8%83%BD%E6%B5%8B%E9%87%8F%E5%92%8C%E5%88%86%E6%9E%90.md)
- [golang pprof 实战](https://link.zhihu.com/?target=https%3A//blog.wolfogre.com/posts/go-ppof-practice/)
- [Go 大杀器之性能剖析 PProf](https://link.zhihu.com/?target=https%3A//eddycjy.com/posts/go/tools/2018-09-15-go-tool-pprof/)
- [Golang 大杀器之跟踪剖析 trace](https://link.zhihu.com/?target=https%3A//juejin.cn/post/6844903887757901831)

# Reference

- CMU 课件 [10-optimization](https://link.zhihu.com/?target=http%3A//www.cs.cmu.edu/afs/cs/academic/class/15213-f15/www/lectures/10-optimization.pdf)
- CMU 电子书、课程等资料地址 [wangmu89/Book-CSAPP: 深入理解计算机系统](https://link.zhihu.com/?target=https%3A//github.com/wangmu89/Book-CSAPP)

- https://github.com/wangmu89/Book-CSAPP)
